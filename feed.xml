<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://maciek-tomczak.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://maciek-tomczak.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-01-02T16:54:58+00:00</updated><id>https://maciek-tomczak.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">Virtuoso Strings Dataset</title><link href="https://maciek-tomczak.github.io/blog/2023/Virtuoso-Strings/" rel="alternate" type="text/html" title="Virtuoso Strings Dataset"/><published>2023-11-10T00:00:00+00:00</published><updated>2023-11-10T00:00:00+00:00</updated><id>https://maciek-tomczak.github.io/blog/2023/Virtuoso-Strings</id><content type="html" xml:base="https://maciek-tomczak.github.io/blog/2023/Virtuoso-Strings/"><![CDATA[]]></content><author><name></name></author><category term="data"/><summary type="html"><![CDATA[I lead the curation of the Virtuoso Strings, a dataset for timing analysis and automatic music transcription (AMT) tasks requiring note onset annotations. This dataset takes advantage of real-world recordings in multitrack format and is curated as a component of the Augmented Reality Music Ensemble (ARME) project. For ISMIR late-breaking demo, please see ismir2023program.ismir.net/lbd_312.html]]></summary></entry><entry><title type="html">Singing Voice Decomposition</title><link href="https://maciek-tomczak.github.io/blog/2021/Singing-Voice-Decomposition/" rel="alternate" type="text/html" title="Singing Voice Decomposition"/><published>2021-09-14T00:00:00+00:00</published><updated>2021-09-14T00:00:00+00:00</updated><id>https://maciek-tomczak.github.io/blog/2021/Singing-Voice-Decomposition</id><content type="html" xml:base="https://maciek-tomczak.github.io/blog/2021/Singing-Voice-Decomposition/"><![CDATA[<h1 id="abstract">Abstract</h1> <blockquote> <p>We investigate how the size of latent variables, functioning as an information bottleneck, affects the reconstruction and disentanglement quality in variational autoencoder (VAE)-based singing voice decomposition. Evaluating a large number of latent variable sizes is impractical due to computational costs. To make this investigation feasible, we first design a VAE that is quick in training and generation and remains stable during training. We then assess the control exerted by different latent variable sizes within our model. For reconstruction quality quantification, we calculate log-spectrogram differences and short-time objective intelligibility (STOI) scores between the ground truth and reconstructed signals. To evaluate disentanglement quality, we train classifiers for each latent variable size to measure the encoded information about generative factors. Our tests on two singing voice datasets, the publicly available NUS English dataset and the newly compiled JP Japanese singing experience database, revealed consistent trends in the impact of latent variable size across both datasets. This suggests the reliability of our results and highlights a trade-off between reconstruction and disentanglement quality. These findings offer insights into the voice conversion capabilities of VAEs and suggest directions for improving VAE-based singing voice decomposition.</p> </blockquote> <h1 id="system-overview">System Overview</h1> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/singing-voice/arch_horizon-480.webp 480w, /_pages/maciek.github.io/singing-voice/arch_horizon-800.webp 800w, /_pages/maciek.github.io/singing-voice/arch_horizon-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/singing-voice/arch_horizon.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p><b>Figure 1:</b> Singing voice decomposition overview with encoders \(E_{\rho}\) and \(E_{c}\) representing low-level information for pitch \(Z_{\rho}\) (orange) and content \(Z_{c}\) (pink) and singer style (i.e., singer ID) \(Z_{\psi}\) (blue). The encoded pitch, content and style information are concatenated onto one latent variable \(z\). The generator \(G\) (yellow) outputs a single log-spectrogram frame. All frames are concatenated together to produce a singing performance. The system is capable of synthesising full singing performances due to dilated CNN architecture.</p> <h1 id="listening-examples">Listening Examples</h1> <p>While listening to the following audio examples, please note that some sonic artifacts are present here and also in other state-of-the-art singing voice conversion methods (e.g., <a href="#ref">[1]</a>). The reduction of such artifacts is not the main target of our research and will be tackled by a research community in the future. Please focus on listening to the conversion of musical characteristics such as timbre and singing style.</p> <p>Please allow a moment if the audio does not load immediately after pressing play.</p> <h2 id="aist-sedb-120jp-database---female-song-13--id-27">AIST-SEDB-120JP database - Female (Song 13 &amp; ID 27)</h2> <p>Each presented audio example follows song and singer IDs in Tables I and II in the paper. All examples are 16-bit 22050 Hz WAV files.</p> <figure> <figcaption><b>Ground truth (female)</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_JP/A_SOURCE_female_JP.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Reconstruction (female)</b></figcaption> <figcaption>Generator trained using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_JP/A_Z4_RECON_female_JP.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Voice Conversion (female &rarr; female)</b></figcaption> <figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_JP/A4_Z4_female_female_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_JP/A3_Z4_female_female_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_JP/A2_Z4_female_female_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_JP/A1_Z4_female_female_JP.mp3" controls=""/> </figure> <figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption> </figure> <figure> <figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption> <figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_JP/A4_Z4_female_male_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_JP/A3_Z4_female_male_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_JP/A2_Z4_female_male_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_JP/A1_Z4_female_male_JP.mp3" controls=""/> </figure> <figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption> </figure> <figure> <figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption> <figcaption>Generator trained using space <b>Zc = 100</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_JP/A1_Z100_female_male_JP.mp3" controls=""/> </figure> <figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption> </figure> <h2 id="aist-sedb-120jp-database---male-song-56--id-04">AIST-SEDB-120JP database - Male (Song 56 &amp; ID 04)</h2> <p>Each presented audio example follows song and singer IDs in Tables I and II in the paper. All examples are 16-bit 22050 Hz WAV files.</p> <figure> <figcaption><b>Ground truth (male)</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_JP/A_SOURCE_male_JP.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Reconstruction (male)</b></figcaption> <figcaption>Generator trained using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_JP/A_Z4_RECON_male_JP.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption> <figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_JP/A4_Z4_male_female_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_JP/A3_Z4_male_female_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_JP/A2_Z4_male_female_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_JP/A1_Z4_male_female_JP.mp3" controls=""/> </figure> <figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption> </figure> <figure> <figcaption><b>Voice Conversion (male &rarr; male)</b></figcaption> <figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_JP/A1_Z4_male_male_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_JP/A3_Z4_male_male_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_JP/A2_Z4_male_male_JP.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_JP/A4_Z4_male_male_JP.mp3" controls=""/> </figure> <figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption> </figure> <figure> <figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption> <figcaption>Generator trained using space <b>Zc = 100</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_JP/A4_Z100_male_female_JP.mp3" controls=""/> </figure> <figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption> </figure> <h2 id="nus-48e-database---female-song-18--id-adiz">NUS-48E database - Female (Song 18 &amp; ID ADIZ)</h2> <p>Each presented audio example follows song and singer IDs in the original NUS-48E database <a href="#ref">[2]</a>. All examples are 16-bit 22050 Hz WAV files.</p> <figure> <figcaption><b>Ground truth (female)</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_EN/A_SOURCE_female_EN.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Reconstruction (female)</b></figcaption> <figcaption>Generator trained using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_EN/A_Z4_RECON_female_EN.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Voice Conversion (female &rarr; female)</b></figcaption> <figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_EN/A4_Z4_female_female_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_EN/A3_Z4_female_female_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_EN/A2_Z4_female_female_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_EN/A1_Z4_female_female_EN.mp3" controls=""/> </figure> <figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption> </figure> <figure> <figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption> <figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_EN/A4_Z4_female_male_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_EN/A3_Z4_female_male_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_EN/A2_Z4_female_male_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_EN/A1_Z4_female_male_EN.mp3" controls=""/> </figure> <figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption> </figure> <figure> <figcaption><b>Voice Conversion (female &rarr; male)</b></figcaption> <figcaption>Generator trained using space <b>Zc = 100</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_female_EN/A1_Z100_female_male_EN.mp3" controls=""/> </figure> <figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption> </figure> <h2 id="nus-48e-database---male-song-15--id-jlee">NUS-48E Database - Male (Song 15 &amp; ID JLEE)</h2> <p>Each presented audio example follows song and singer IDs in the original NUS-48E database <a href="#ref">[2]</a>. All examples are 16-bit 22050 Hz WAV files.</p> <figure> <figcaption><b>Ground truth (male)</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_EN/A_SOURCE_male_EN.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Reconstruction (male)</b></figcaption> <figcaption>Generator trained using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_EN/A_Z4_RECON_male_EN.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption> <figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_EN/A4_Z4_male_female_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_EN/A3_Z4_male_female_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_EN/A2_Z4_male_female_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_EN/A1_Z4_male_female_EN.mp3" controls=""/> </figure> <figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption> </figure> <figure> <figcaption><b>Voice Conversion (male &rarr; male)</b></figcaption> <figcaption>4 examples generated with a trained model using space <b>Zc = 4</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_EN/A1_Z4_male_male_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_EN/A3_Z4_male_male_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_EN/A2_Z4_male_male_EN.mp3" controls=""/> </figure> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_EN/A4_Z4_male_male_EN.mp3" controls=""/> </figure> <figcaption>Above examples show varied timbres and successful conversions to different singers</figcaption> </figure> <figure> <figcaption><b>Voice Conversion (male &rarr; female)</b></figcaption> <figcaption>Generator trained using space <b>Zc = 100</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/singing-voice/A_male_EN/A4_Z100_male_female_EN.mp3" controls=""/> </figure> <figcaption>Example sounds almost the same as the ground truth with <b>no voice conversion</b></figcaption> </figure> <h1 id="references"><a name="ref">References</a></h1> <p>[1] <a href="https://ismir19-217.github.io/icassp20-audio-sample/">Yin-Jyun Luo et al. “Singing voice conversion with disentangled representations of singer and vocal technique using variational autoencoders”. In: IEEE international conference on acoustics, speech and signal processing (ICASSP). 2020.</a></p> <p>[2] <a href="https://smcnus.comp.nus.edu.sg/nus-48e-sung-and-spoken-lyrics-corpus/">Zhiyan Duan et al. “The NUS sung and spoken lyrics corpus: a quantitative comparison of singing and speech”. In: IEEE Asia-pacific signal and informationprocessing association annual summit and conference (APSIPA ASC). 2013.</a></p>]]></content><author><name></name></author><category term="ML"/><summary type="html"><![CDATA[Audio examples accompanying an unpublished paper titled Investigating Information Bottleneck in Variational Autoencoder-based Singing Voice Decomposition which I worked on with Kin Wah Edward Lin (AIST), Tomoyasu Nakano (AIST), Jason Hockman (BCU), and Masataka Goto (AIST)]]></summary></entry><entry><title type="html">Drum Synthesis and Rhythmic Transformation with Adversarial Autoencoders</title><link href="https://maciek-tomczak.github.io/blog/2020/Drum-Synthesis-and-Rhythmic-Transformation/" rel="alternate" type="text/html" title="Drum Synthesis and Rhythmic Transformation with Adversarial Autoencoders"/><published>2020-07-01T00:00:00+00:00</published><updated>2020-07-01T00:00:00+00:00</updated><id>https://maciek-tomczak.github.io/blog/2020/Drum-Synthesis-and-Rhythmic-Transformation</id><content type="html" xml:base="https://maciek-tomczak.github.io/blog/2020/Drum-Synthesis-and-Rhythmic-Transformation/"><![CDATA[<table> <tbody> <tr> <td><strong><a href="https://maciek-tomczak.github.io/">Tomczak, M.</a>, <a href="https://staff.aist.go.jp/m.goto/">M., Goto</a>, <a href="https://www.schoolofdigitalarts.mmu.ac.uk/staff/jason-hockman/">J., Hockman</a>, <a href="https://doi.org/10.1145/3394171.3413519">Drum Synthesis and Rhythmic Transformation with Adversarial Autoencoders, Proceedings of the 28th ACM International Conference on Multimedia (ACM MM), Seattle, WA, USA, October 12–16, 2020.</a></strong></td> </tr> </tbody> </table> <p>Work conducted during an internship at <a href="https://staff.aist.go.jp/m.goto/MIG/index-j.html">Media Interaction Group</a>, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan.</p> <center> <iframe width="560" height="315" src="https://www.youtube.com/embed/6aXRdDeihIc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </center> <h3 id="1-audio-synthesis-with-trained-generator-g">1. Audio synthesis with trained generator (G)</h3> <p>We demonstrate reconstruction of bar-length drum patterns from the generator model trained on real drum recordings. Examples at 22.05kHz sample rate are recreated with Griffin-Lim algorithm together with their corresponding output from the proposed AAE-GM model. More detailed information about data used here can be viewed in Section 3.1 of the <a href="https://doi.org/10.1145/3394171.3413519">paper</a>.</p> <figure> <figcaption><b>Source</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0092/source_GL-0092_392.mp3" controls=""/> </figure> <figcaption><b>Output Reconstruction</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0092/0092_392.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Source</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0026/source_GL-0026_64.mp3" controls=""/> </figure> <figcaption><b>Output Reconstruction</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0026/0026_64.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Source</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0070/source_GL-0070_862.mp3" controls=""/> </figure> <figcaption><b>Output Reconstruction</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0070/0070_862.mp3" controls=""/> </figure> </figure> <h3 id="2-latent-space-interpolation">2. Latent Space Interpolation</h3> <figure> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/ACM20_audio/interp_b-480.webp 480w, /_pages/maciek.github.io/ACM20_audio/interp_b-800.webp 800w, /_pages/maciek.github.io/ACM20_audio/interp_b-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/ACM20_audio/interp_b.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption><b>Figure: Interpolation between two rhythmic patterns from source to target</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/16-interp-short.mp3" controls=""/> </figure> </figure> <p>The proposed model performs rhythmic transformation of bar-length drum patterns as follows:</p> <ul> <li>Generator reconstruction of <strong>source input</strong></li> <li>Transformation into an <strong>intermediate rhythmic pattern</strong></li> <li>Resulting <strong>output transformation</strong></li> </ul> <p>A user is given the freedom to manipulate the structure within a bar without reliance on discrete identification of rhythmic boundaries towards a continuous transformation.</p> <ul> <li>Interpolations in the latent space allow for the mixing of two different drum patterns</li> <li>A gradual change is achievable from the <strong>source</strong> rhythmic pattern to the <strong>target</strong> pattern</li> <li>The <strong>intermediate latent codes</strong> are produced using a linear interpolation between <strong>source</strong> and <strong>target</strong> latent codes</li> </ul> <figure> <figcaption><b>Source Recording</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0026_to_0012/source_GL-0026_64.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Stage 1 | α = 0.0</b></figcaption> <figcaption><b>Source reconstructed with generator G (not interpolated)</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0026_to_0012/interp0_alpha0.0.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Stage 2 | α = 0.25</b></figcaption> <figcaption><b>This example is similar to source, but begins to be transformed closer to target</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0026_to_0012/interp1_alpha0.25.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Stage 3 | α = 0.5</b></figcaption> <figcaption><b>This example is just in-between the source and the target pattern</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0026_to_0012/interp2_alpha0.5.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Stage 4 | α = 0.75</b></figcaption> <figcaption><b>This example begins to be more rhythmically similar to the target pattern</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0026_to_0012/interp3_alpha0.75.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Stage 5 | α = 1.0</b></figcaption> <figcaption><b>Target reconstructed with generator G (not interpolated)</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0026_to_0012/interp4_alpha1.0.mp3" controls=""/> </figure> </figure> <figure> <figcaption><b>Target Recording</b></figcaption> <figure> <audio src="/_pages/maciek.github.io/ACM20_audio/0026_to_0012/target_GL-0012_1611.mp3" controls=""/> </figure> </figure>]]></content><author><name></name></author><category term="redrumming"/><category term="ML"/><summary type="html"><![CDATA[Audio examples accompanying paper for ACM International Conference on Multimedia (ACM MM) 2020.]]></summary></entry><entry><title type="html">Drum Translation for Timbral and Rhythmic Transformation</title><link href="https://maciek-tomczak.github.io/blog/2019/Drum-Translation-for-Timbral-and-Rhythmic-Transformation/" rel="alternate" type="text/html" title="Drum Translation for Timbral and Rhythmic Transformation"/><published>2019-04-12T00:00:00+00:00</published><updated>2019-04-12T00:00:00+00:00</updated><id>https://maciek-tomczak.github.io/blog/2019/Drum-Translation-for-Timbral-and-Rhythmic-Transformation</id><content type="html" xml:base="https://maciek-tomczak.github.io/blog/2019/Drum-Translation-for-Timbral-and-Rhythmic-Transformation/"><![CDATA[<table> <tbody> <tr> <td><strong><a href="https://maciek-tomczak.github.io/">Tomczak, M.</a>., <a href="https://scholar.google.ch/citations?user=t2Zm6aoAAAAJ&amp;hl=en&amp;oi=ao">J., Drysdale</a>, <a href="https://www.schoolofdigitalarts.mmu.ac.uk/staff/jason-hockman/">J., Hockman</a>, <a href="http://dafx2019.bcu.ac.uk/papers/DAFx2019_paper_25.pdf">Drum Translation for Timbral and Rhythmic Transformation, Proceedings of the 22nd International Conference on Digital Audio Effects (DAFx), Birmingham, United Kingdom, September 2–6, 2019.</a></strong></td> </tr> </tbody> </table> <p>Poster available <a href="https://drive.google.com/file/d/1lnoi15T9eiIq_hwO8d7AB6Ow2BEx7Jm_/view?usp=sharing">here</a>.</p> <h3 id="audio-examples">Audio examples</h3> <ul> <li>6 transformations created with the proposed automatic drum translation system</li> <li>20 transformation pairs used in rhythmic evaluation of the system (Sections 3.2 and 4.1 in the <a href="http://dafx2019.bcu.ac.uk/papers/DAFx2019_paper_25.pdf">paper</a>)</li> </ul> <center><h3>Audio Examples</h3></center> <center> <figure> <figcaption>Automatic drum translation 1/6</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/src/src1.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/redrummings/redrumming1.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Automatic drum translation 2/6</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/src/src2.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/redrummings/redrumming2.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Automatic drum translation 3/6</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/src/src3.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/redrummings/redrumming3.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Automatic drum translation 4/6</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/src/src4.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/redrummings/redrumming4.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Automatic drum translation 5/6</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/src/src5.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/redrummings/redrumming5.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Automatic drum translation 6/6</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/src/src6.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/adt-dt/redrummings/redrumming6.mp3" controls=""/> </figure> </div> </div> </figure> </center> <hr/> <center> <figure> <figcaption>Drum Translation 1/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source16.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation16.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 2/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source19.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation19.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 3/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source15.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation15.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 4/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source18.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation18.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 5/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source14.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation14.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 6/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source13.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation13.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 7/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source10.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation10.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 8/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source1.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation1.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 9/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source11.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation11.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 10/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source12.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation12.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 11/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source17.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation17.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 12/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source2.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation2.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 13/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source20.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation20.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 14/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source3.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation3.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 15/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source4.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation4.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 16/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source5.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation5.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 17/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source6.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation6.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 18/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source7.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation7.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 19/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source8.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation8.mp3" controls=""/> </figure> </div> </div> </figure> <figure> <figcaption>Drum Translation 20/20</figcaption> <figcaption>Source recording (left) and translation output (right)</figcaption> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/input/source9.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/_pages/maciek.github.io/DAFx19_audio/output/translation9.mp3" controls=""/> </figure> </div> </div> </figure> </center>]]></content><author><name></name></author><category term="wavenet"/><category term="redrumming"/><category term="ML"/><summary type="html"><![CDATA[Results supplementing the paper for the International Conference on Digital Audio Effects (DAFx) 2019.]]></summary></entry><entry><title type="html">Audio Style Transfer with Rhythmic Constraints</title><link href="https://maciek-tomczak.github.io/blog/2018/Audio-Style-Transfer-with-Rhythmic-Constraints/" rel="alternate" type="text/html" title="Audio Style Transfer with Rhythmic Constraints"/><published>2018-04-16T00:00:00+00:00</published><updated>2018-04-16T00:00:00+00:00</updated><id>https://maciek-tomczak.github.io/blog/2018/Audio-Style-Transfer-with-Rhythmic-Constraints</id><content type="html" xml:base="https://maciek-tomczak.github.io/blog/2018/Audio-Style-Transfer-with-Rhythmic-Constraints/"><![CDATA[<table> <tbody> <tr> <td><strong><a href="https://maciek-tomczak.github.io/">Tomczak, M.</a>, <a href="https://scholar.google.co.uk/citations?user=BrvdPboAAAAJ&amp;hl=en">C., Southall</a>, <a href="https://www.schoolofdigitalarts.mmu.ac.uk/staff/jason-hockman/">J., Hockman</a>, <a href="https://ant-s4.unibw-hamburg.de/dafx/paper-archive/2018/papers/DAFx2018_paper_48.pdf">Audio Style Transfer with Rhythmic Constraints, Proceedings of the 21st International Conference on Digital Audio Effects (DAFx), Aveiro, Portugal, September 4–8, 2018.</a></strong></td> </tr> </tbody> </table> <h3 id="audio-examples">Audio examples</h3> <p>The presented 15 transformation pairs were tested with 3 different loss terms L1, L2 and L3 defined in the <a href="https://ant-s4.unibw-hamburg.de/dafx/paper-archive/2018/papers/DAFx2018_paper_48.pdf">paper</a>, as well as, several additional audio style transfer (AST) transformations. In addition, transformations acquired with default parameters from AST approaches by Barry et al. (2018), Mital (2017) and Ulyanov et al. (2016) are included with the results. Inputs A and B refer to terms <i>content</i> and <i>style</i> used by the authors of the compared papers.</p> <p>Mashup transformations using L2.</p> <center> <figure> <figcaption><b>Input A</b>: Marching In The Streets by Harvey Mason</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/samples/Harvey_Mason_Marching_In_The_Streets.mp3" controls=""/> </figure> <figcaption><b>Input B</b>: Night and Day by Idris Muhammad with George Coleman</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/samples/Idris_Muhammad_with_George_Coleman_Night_and_Day.mp3" controls=""/> </figure> <figcaption><b>Output Loss 2</b> (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/jazz/Harvey_Mason_Marching_In_The_StreetsIdris_Muhammad_with_George_Coleman_Night_and_Day_1_exp1_fullnorm.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <figure> <figcaption><b>Input A</b>: Colours of the Season by Daudi Matsiko, Yung Veerp, Fazerdaze and others</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/samples/colours_of_the_season.mp3" controls=""/> </figure> <figcaption><b>Input B</b>: Loop Trigger by Mathew Jonson, GPU Panic</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/samples/loop_trigger.mp3" controls=""/> </figure> <figcaption><b>Output Loss 2</b> - Loop Triggered Colours of the Season</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/loop_triggered_colors_of_the_season.mp3" controls=""/> </figure> </figure> </center> <hr/> <p>Transformation comparisons.</p> <center> <h3> Pair 1 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_ep_02mason_br_02_3_exp3_fullnorm05.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_ep_02mason_br_02_3_exp3_fullnorm05.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_ep_02mason_br_02_3_exp3_fullnorm05.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_ep_02mason_br_02_3_exp3_fullnorm05.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_ep_02mason_br_02_3_exp3_fullnorm05.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_ep_02mason_br_02_3_exp3_fullnorm04.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_ep_02mason_br_02_3_exp3_fullnorm04.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_ep_02mason_br_02_3_exp3_fullnorm04.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 2 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_gs_02mason_cl_03_8_exp8_fullnorm08.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_gs_02mason_cl_03_8_exp8_fullnorm08.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_gs_02mason_cl_03_8_exp8_fullnorm08.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_gs_02mason_cl_03_8_exp8_fullnorm08.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_gs_02mason_cl_03_8_exp8_fullnorm08.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_gs_02mason_cl_03_8_exp8_fullnorm07.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_gs_02mason_cl_03_8_exp8_fullnorm07.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_gs_02mason_cl_03_8_exp8_fullnorm07.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 3 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_hp_02mason_cl_01_10_exp10_fullnorm10.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_hp_02mason_cl_01_10_exp10_fullnorm10.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_hp_02mason_cl_01_10_exp10_fullnorm10.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_hp_02mason_cl_01_10_exp10_fullnorm10.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_hp_02mason_cl_01_10_exp10_fullnorm10.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_hp_02mason_cl_01_10_exp10_fullnorm09.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_hp_02mason_cl_01_10_exp10_fullnorm09.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_hp_02mason_cl_01_10_exp10_fullnorm09.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 4 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_mt_03mason_br_01_12_exp12_fullnorm13.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_mt_03mason_br_01_12_exp12_fullnorm13.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_mt_03mason_br_01_12_exp12_fullnorm13.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_mt_03mason_br_01_12_exp12_fullnorm13.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_mt_03mason_br_01_12_exp12_fullnorm13.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_mt_03mason_br_01_12_exp12_fullnorm12.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_mt_03mason_br_01_12_exp12_fullnorm12.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_mt_03mason_br_01_12_exp12_fullnorm12.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 5 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_nk_01kyle_hp_01_4_exp4_fullnorm14.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_nk_01kyle_hp_01_4_exp4_fullnorm14.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_nk_01kyle_hp_01_4_exp4_fullnorm14.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_nk_01kyle_hp_01_4_exp4_fullnorm14.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_nk_01kyle_hp_01_4_exp4_fullnorm14.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_nk_01kyle_hp_01_4_exp4_fullnorm13.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_nk_01kyle_hp_01_4_exp4_fullnorm13.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_nk_01kyle_hp_01_4_exp4_fullnorm13.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 6 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/mason_br_03mason_km_03_13_exp13_fullnorm15.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/mason_br_03mason_km_03_13_exp13_fullnorm15.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/mason_br_03mason_km_03_13_exp13_fullnorm15.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/mason_br_03mason_km_03_13_exp13_fullnorm15.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/mason_br_03mason_km_03_13_exp13_fullnorm15.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/mason_br_03mason_km_03_13_exp13_fullnorm14.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/mason_br_03mason_km_03_13_exp13_fullnorm14.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/mason_br_03mason_km_03_13_exp13_fullnorm14.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 7 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/mason_e_03kyle_ob_03_14_exp14_fullnorm16.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/mason_e_03kyle_ob_03_14_exp14_fullnorm16.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/mason_e_03kyle_ob_03_14_exp14_fullnorm16.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/mason_e_03kyle_ob_03_14_exp14_fullnorm16.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/mason_e_03kyle_ob_03_14_exp14_fullnorm16.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/mason_e_03kyle_ob_03_14_exp14_fullnorm15.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/mason_e_03kyle_ob_03_14_exp14_fullnorm15.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/mason_e_03kyle_ob_03_14_exp14_fullnorm15.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 8 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_ctp_02kyle_nk_03_1_exp1_fullnorm04.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_ctp_02kyle_nk_03_1_exp1_fullnorm04.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_ctp_02kyle_nk_03_1_exp1_fullnorm04.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_ctp_02kyle_nk_03_1_exp1_fullnorm04.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_ctp_02kyle_nk_03_1_exp1_fullnorm04.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_ctp_02kyle_nk_03_1_exp1_fullnorm03.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_ctp_02kyle_nk_03_1_exp1_fullnorm03.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_ctp_02kyle_nk_03_1_exp1_fullnorm03.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 9 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_ep_01kyle_ob_02_2_exp2_fullnorm02.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_ep_01kyle_ob_02_2_exp2_fullnorm02.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_ep_01kyle_ob_02_2_exp2_fullnorm02.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_ep_01kyle_ob_02_2_exp2_fullnorm02.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_ep_01kyle_ob_02_2_exp2_fullnorm02.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_ep_01kyle_ob_02_exp2_fullnorm01.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_ep_01kyle_ob_02_exp2_fullnorm01.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_ep_01kyle_ob_02_exp2_fullnorm01.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 10 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_ep_03kyle_hp_03_5_exp5_fullnorm06.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_ep_03kyle_hp_03_5_exp5_fullnorm06.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_ep_03kyle_hp_03_5_exp5_fullnorm06.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_ep_03kyle_hp_03_5_exp5_fullnorm06.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_ep_03kyle_hp_03_5_exp5_fullnorm06.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_ep_03kyle_hp_03_5_exp5_fullnorm05.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_ep_03kyle_hp_03_5_exp5_fullnorm05.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_ep_03kyle_hp_03_5_exp5_fullnorm05.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 11 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_gs_01mason_km_02_6_exp6_fullnorm07.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_gs_01mason_km_02_6_exp6_fullnorm07.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_gs_01mason_km_02_6_exp6_fullnorm07.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_gs_01mason_km_02_6_exp6_fullnorm07.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_gs_01mason_km_02_6_exp6_fullnorm07.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_gs_01mason_km_02_6_exp6_fullnorm06.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_gs_01mason_km_02_6_exp6_fullnorm06.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_gs_01mason_km_02_6_exp6_fullnorm06.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 12 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_gs_03mason_e_02_9_exp9_fullnorm09.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_gs_03mason_e_02_9_exp9_fullnorm09.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_gs_03mason_e_02_9_exp9_fullnorm09.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_gs_03mason_e_02_9_exp9_fullnorm09.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_gs_03mason_e_02_9_exp9_fullnorm09.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_gs_03mason_e_02_9_exp9_fullnorm08.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_gs_03mason_e_02_9_exp9_fullnorm08.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_gs_03mason_e_02_9_exp9_fullnorm08.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 13 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_ctp_01kyle_nk_02_0_exp0_fullnorm03.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_ctp_01kyle_nk_02_0_exp0_fullnorm03.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_ctp_01kyle_nk_02_0_exp0_fullnorm03.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_ctp_01kyle_nk_02_0_exp0_fullnorm03.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_ctp_01kyle_nk_02_0_exp0_fullnorm03.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_ctp_01kyle_nk_02_0_exp0_fullnorm02.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_ctp_01kyle_nk_02_0_exp0_fullnorm02.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_ctp_01kyle_nk_02_0_exp0_fullnorm02.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 14 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_mt_01mason_km_01_7_exp7_fullnorm11.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_mt_01mason_km_01_7_exp7_fullnorm11.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_mt_01mason_km_01_7_exp7_fullnorm11.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_mt_01mason_km_01_7_exp7_fullnorm11.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_mt_01mason_km_01_7_exp7_fullnorm11.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_mt_01mason_km_01_7_exp7_fullnorm10.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_mt_01mason_km_01_7_exp7_fullnorm10.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_mt_01mason_km_01_7_exp7_fullnorm10.mp3" controls=""/> </figure> </figure> </center> <hr/> <center> <h3> Pair 15 </h3> <figure> <figcaption>Input A</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputA/kyle_nk_01kyle_hp_01_4_exp4_fullnorm14.mp3" controls=""/> </figure> <figcaption>Input B</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/inputB/kyle_nk_01kyle_hp_01_4_exp4_fullnorm14.mp3" controls=""/> </figure> <figcaption>Loss 1 (Vanilla AST - Content A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L1/out/kyle_nk_01kyle_hp_01_4_exp4_fullnorm14.mp3" controls=""/> </figure> <figcaption>Loss 2 (Mashup - Style A + Style B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L2/out/kyle_nk_01kyle_hp_01_4_exp4_fullnorm14.mp3" controls=""/> </figure> <figcaption>Loss 3 (Augmented Mashup - Style A + Style B + Content B)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/results/L3/out/kyle_nk_01kyle_hp_01_4_exp4_fullnorm14.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Barry 2018)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/barry/mp3/kyle_nk_01kyle_hp_01_4_exp4_fullnorm13.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Mital 2017)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/mital/mp3/kyle_nk_01kyle_hp_01_4_exp4_fullnorm13.mp3" controls=""/> </figure> <figcaption>Vanilla AST (Ulyanov 2016)</figcaption> <figure> <audio src="/_pages/maciek.github.io/DAFx18_audio/ulyanov/mp3/kyle_nk_01kyle_hp_01_4_exp4_fullnorm13.mp3" controls=""/> </figure> </figure> </center> <hr/> <h3 id="references">References:</h3> <ol> <li> <p>Shaun Barry and Youngmoo Kim, “Style transfer for musical audio using multiple time-frequency representations,” 2018, Available at: <a href="https://github.com/pkmital/time-domain-neural-audio-style-transfer">https://github.com/anonymousiclr2018/Style-Transfer-for-Musical-Audio</a>.</p> </li> <li> <p>Parag K. Mital, “Time domain neural audio style transfer,” 2017, Available at: <a href="https://github.com/pkmital/time-domain-neural-audio-style-transfer">https://github.com/pkmital/time-domain-neural-audio-style-transfer</a>.</p> </li> <li> <p>Dmitry Ulyanov and Vadim Lebedev, “Audio texture synthesis and style transfer,” 2016, Available at: <a href="https://github.com/pkmital/time-domain-neural-audio-style-transfer">https://dmitryulyanov.github.io/audio-texture-synthesis-and-style-transfer/</a>.</p> </li> </ol>]]></content><author><name></name></author><category term="audio-style-transfer"/><category term="redrumming"/><category term="ML"/><summary type="html"><![CDATA[Results supplementing the paper for the International Conference on Digital Audio Effects (DAFx) 2018.]]></summary></entry><entry><title type="html">Kurs Realizatorów Fandubbingowych</title><link href="https://maciek-tomczak.github.io/blog/2016/KRF/" rel="alternate" type="text/html" title="Kurs Realizatorów Fandubbingowych"/><published>2016-07-04T00:00:00+00:00</published><updated>2016-07-04T00:00:00+00:00</updated><id>https://maciek-tomczak.github.io/blog/2016/KRF</id><content type="html" xml:base="https://maciek-tomczak.github.io/blog/2016/KRF/"><![CDATA[]]></content><author><name></name></author><category term="fandubbing"/><summary type="html"><![CDATA[Kurs pokrywa wstęp do miksowania i masteringu projektów wokalnych w kontekście piosenek fandubbingowych. Kurs przeznaczony jest głównie dla realizatorów dźwięku, dźwiękowców i reżyserów piosenek. Osoby aspirujące do wdrożenia się w świat post-produkcji znajdą dobry wstęp do podstawowych technik miksowania i pracy z piosenkami fandubbingowymi. Doświadczeni realizatorzy dźwięku też mogą znaleźć coś co ich zainteresuje. Oczywiście zachęcam do przejrzenia kursu wszystkich zainteresowanych śpiewaniem, nagrywaniem i post-produkcją nagrań wokalnych.]]></summary></entry><entry><title type="html">The Magik Smiftheniser Plug-in</title><link href="https://maciek-tomczak.github.io/blog/2015/Smiftheniser-Plugin/" rel="alternate" type="text/html" title="The Magik Smiftheniser Plug-in"/><published>2015-04-01T00:00:00+00:00</published><updated>2015-04-01T00:00:00+00:00</updated><id>https://maciek-tomczak.github.io/blog/2015/Smiftheniser-Plugin</id><content type="html" xml:base="https://maciek-tomczak.github.io/blog/2015/Smiftheniser-Plugin/"><![CDATA[<p>Have you ever wanted of an audio plugin that can make your songs colder or punchier? Look no more!</p> <p>I present to you <em>The Magik Smiftheniser Plug-in.</em></p> <p>The Magik Smiftheniser Plug-in developed using <a href="https://www.willpirkle.com/rackafx/">RackAFX</a>.</p> <center> <iframe width="560" height="315" src="https://www.youtube.com/embed/miDvbmyl2mg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/smiftheniser-plugin/smifplugin2-480.webp 480w, /_pages/maciek.github.io/smiftheniser-plugin/smifplugin2-800.webp 800w, /_pages/maciek.github.io/smiftheniser-plugin/smifplugin2-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/smiftheniser-plugin/smifplugin2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center>]]></content><author><name></name></author><category term="DSP"/><category term="RackAFX"/><summary type="html"><![CDATA[Not-an-April-Fool's-brain-modelling-audio-plugin.]]></summary></entry><entry><title type="html">Aligning Vocals - Drudgery or a Walk in the Park?</title><link href="https://maciek-tomczak.github.io/blog/2014/Aligning-Vocals/" rel="alternate" type="text/html" title="Aligning Vocals - Drudgery or a Walk in the Park?"/><published>2014-12-20T00:00:00+00:00</published><updated>2014-12-20T00:00:00+00:00</updated><id>https://maciek-tomczak.github.io/blog/2014/Aligning-Vocals</id><content type="html" xml:base="https://maciek-tomczak.github.io/blog/2014/Aligning-Vocals/"><![CDATA[<p>I wrote the following article back in 2013 and today the problem of aligning things in time is still very close to my heart.</p> <p>Original article is posted <a href="https://maciekonsound.wordpress.com/2014/12/19/aligning-vocals-drudgery-or-a-walk-in-the-park/">here</a>.</p> <h4 id="aligning-vocals---drudgery-or-a-walk-in-the-park">Aligning Vocals - Drudgery or a walk in the park?</h4> <div class="entry-content"> This time I want to show you a vocal aligning plugin I’ve recently found and started using like a madman. Knowing that I often work with tracks that I need to have aligned pretty tight, this discovery was just what I needed. When I think of all the long ‘late’ hours spent on aligning vocals in software such as <a href="http://www.celemony.com/en/melodyne/what-is-melodyne" target="_blank">Melodyne</a> I get these uncomfortable chills on my back, ughh. Oh man, why didn’t I know about VocAlign before?! Well there is a good reason for it. I just wasn’t looking for it! To be honest I would be probably still working with software like Melodyne till this day if my friend hadn’t told me about it, but about that in a second. So, I wanted to think that the software just wasn’t around until recently but here came a surprise for me. Apparently the VocAlign project was first released in 2001 and now grew to see its new version which is available <a href="https://www.synchroarts.com/products/vocalign-pro/overview" target="_blank">here</a>. One day I talked with my friend about timing vocals to one of the songs I was working on and (of course) I’d go on, and on about how annoying working with Melodyne can be. It can very easily destroy the signal making it sound like, hmm, well like Melodyne. Well, from time to time the vocals I work on need to sound alien-like, but hey welcome to the 21st century! Sometimes alien-like vocals may be the thing that the song calls for, right? With many popular songs nowadays you simply cannot tell if the vocals were actually sang by an actual human being. But back to the story. My friend answered to my complaining with a question ’why don’t you just use VocAlign for your tracks?’. I wasn’t completely aware at the time of how that conversation will change the way I handle vocal aligning. but now, I know, and I am really excited to share some of my results. So what’s VocAlign? It is an audio plugin that will automatically align two audio signals so that the timing of one matches the other. It works at 16 and 24 bit resolutions and sampling frequencies from 44.1 to 192kHz. But what truly maters is the simplicity and speed of the software. The work that was taking me an hour using Melodyne for example, decreased now to only few minutes. Don’t get me wrong, I still think Melodyne is a great piece of software and I still use it often, but so far VocAlign has made vocal aligning to me be just like a walk in the park. <strong>Aligning with VocAlign: Examples</strong> I will present 3 different examples that will consist of: 1) an .mp3 containing just a raw vocal tracks, 2) .mp3 containing vocal VocAligned tracks and 3) the mixed track. <center> <figure> <div class="caption"> Example 1 No Effects </div> <figure> <audio src="/_pages/maciek.github.io/aligning-vocals/Example_1_NoEffects.mp3" controls=""/> </figure> <div class="caption"> Example 1 VocAlign </div> <figure> <audio src="/_pages/maciek.github.io/aligning-vocals/Example_1_VocAlign.mp3" controls=""/> </figure> <div class="caption"> Example 1 Mix </div> <figure> <audio src="/_pages/maciek.github.io/aligning-vocals/Example_1_Mix.mp3" controls=""/> </figure> </figure> </center> The differences between not aligned and aligned tracks may be subtle in this example but I wanted to show it anyways because many things mastering engineers do, Are subtle. I learned that from Dave Pensado and his amazing series on YT called <a href="http://www.pensadosplace.tv/" target="_blank">Pensado’s Place</a>. Defnitely worth checking out if you are into music production, sound engineering, mastering, or anything else that has something to do with studio work. So in this example we will see how VocAlign deals with a bit more recognisable timing variations. <center> <figure> <div class="caption"> Example 2 No Effects </div> <figure> <audio src="/_pages/maciek.github.io/aligning-vocals/Example_2_NoEffects.mp3" controls=""/> </figure> <div class="caption"> Example 2 VocAlign </div> <figure> <audio src="/_pages/maciek.github.io/aligning-vocals/Example_2_VocAlign.mp3" controls=""/> </figure> <div class="caption"> Example 2 Mix </div> <figure> <audio src="/_pages/maciek.github.io/aligning-vocals/Example_2_Mix.mp3" controls=""/> </figure> </figure> </center> In this example you can hear the differences much better (if you still can’t hear it then listen out for the word ‘hearts’) Now I will just quickly write down the process I have to go through to align one track to the other: 1) Open VocAlign, 2) side chain the track I’m working on to the track that I want to align it to, 3) click ‘Capture Audio’, 4) playback the part that I want to align, 5) press ‘Analyse’&gt;’Align’&gt;’Edit’ and voilà, I have my aligned track. Excluding the playback time the whole process takes me a few seconds. How amazing is that?! Definitely much better than moving each syllable manually. But of course nothing is perfect (That's a good thing. SMILEY) <strong>Where does a subtle (=’good’) aligning end and where does a hardcore (=’not so good’) aligning start?</strong> <center> <figure> <div class="caption"> Example 3 No Effects </div> <figure> <audio src="/_pages/maciek.github.io/aligning-vocals/Example_3_NoEffects.mp3" controls=""/> </figure> <div class="caption"> Example 3 VocAlign </div> <figure> <audio src="/_pages/maciek.github.io/aligning-vocals/Example_3_VocAlign.mp3" controls=""/> </figure> </figure> </center> What was wrong? You can probably tell yourself already. Well, VocAlign uses sophisticated pattern matching algorithms that compare digital data. VocAlign moves AND stretches our recording so that it creates as closest match as possible to the side chained track. The obvious problem that arrises is this ‘unnaturally-stretchy-signal’ (probably the best way to describe it :) Do we want it? Maybe yes, maybe not. In the end, I worked my way to have it sound like this: <center> <figure> <div class="caption"> Example 3 Mix </div> <figure> <audio src="/_pages/maciek.github.io/aligning-vocals/Example_3_Mix.mp3" controls=""/> </figure> </figure> </center> Furthermore, in example 3 you should also notice the word timing differences. These may cause more problems if one is not careful. <strong>The Bottom Line</strong> <ul> <li>I no longer have to waste my time aligning each syllable of my layered vocals.</li> <li>Working with backing vocals has never been easier.</li> <li>Yes, VocAlign sometimes does this weird stretchy thing to the signal, but so what?  I’m ready to forgive these little flaws if the process of aligning, as a whole, has been reduced to just a few mouse clicks.</li> </ul> I still use both <a href="http://www.celemony.com/en/melodyne/what-is-melodyne" target="_blank">Melodyne by Celemony</a> and <a href="https://www.synchroarts.com/products/vocalign-pro/overview" target="_blank">VocAlign by Synchro Arts</a> and I'm really interested in what the future research holds for automatic vocal alignment and manipulation. This is the band that I used for the above examples, Make Sure You Check Their YT Channel: <a href="http://www.youtube.com/user/JetfaceGroup" target="_blank" rel="nofollow">JetfaceGroup – YouTube</a> </div> <h3></h3> <p>Maciek</p>]]></content><author><name></name></author><category term="vocal-alignment"/><category term="mixing"/><summary type="html"><![CDATA[On manual and automatic alignment of vocal recordings.]]></summary></entry><entry><title type="html">Audio Compression Quality</title><link href="https://maciek-tomczak.github.io/blog/2014/Audio-Compression-Quality/" rel="alternate" type="text/html" title="Audio Compression Quality"/><published>2014-12-19T00:00:00+00:00</published><updated>2014-12-19T00:00:00+00:00</updated><id>https://maciek-tomczak.github.io/blog/2014/Audio-Compression-Quality</id><content type="html" xml:base="https://maciek-tomczak.github.io/blog/2014/Audio-Compression-Quality/"><![CDATA[<p>I wrote the following article back when I was an undergrad finishing my first year at Birmingham City University in 2013. Coincidentally, to my surprise the same experiment I describe here was given to me in class by my DSP professor Ian Williams a few weeks after I published this. Anyway, after revisiting these tests more recently I can sum them up with the good ol’ <em>it depends</em> :)</p> <p><strong>TL;DR</strong> A 320kbps VBR Mp3 can be enough but it depends to what you are listening to and what system you are listening that on.</p> <p>Original article is posted <a href="https://maciekonsound.wordpress.com/2014/12/19/listening-tests/">here</a>.</p> <h2>Listening Tests</h2> <p style="text-align:left;" align="CENTER">So in the previous <a title="Article on CD Ripping" href="https://maciek-tomczak.github.io/maciek.github.io/Audio-Ripping-and-Compression" target="_blank">article</a> we managed to rip and compress our really good quality Mp3s. So now its right time to ask questions… Just how good are these Mp3s if compared to the sound on a CD? Have we set up the encoder correctly? The most obvious way to find out is to conduct a listening test, but…</p> <p>But there is a problem.</p> <p>It turns out that it is quite challenging to compare two audio sources of different quality, timing, and volume. The traditional method of audio listening tests is to play one song followed by another and ask which one sounded better. Interestingly enough, our brains recognize a slight increase in volume as an increase in clarity, which is critical in this situation, as we want to avoid possibility of confirmation bias. We need a way of switching between two audio sources of different quality at any point in a song, with no delays or changes in timing and volume.</p> <p>I’ve observed many fierce debates in real live and online, where people insisted that they can hear the difference between 320kbps Mp3s and ones of even slightly lower bit rate. Some say that Mp3s are no good enough for ‘serious’ audio equipment. Let’s hear if this is true.</p> <p>I ripped one song from the same CD as an uncompressed wave file, as a 320 bit rate Mp3 and as the blend of VBR.</p> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/audio-compression/11-480.webp 480w, /_pages/maciek.github.io/audio-compression/11-800.webp 800w, /_pages/maciek.github.io/audio-compression/11-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/audio-compression/11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p>I imported the raw wave file and the 320kbps Mp3 into Audacity, one after the other.</p> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/audio-compression/21-480.webp 480w, /_pages/maciek.github.io/audio-compression/21-800.webp 800w, /_pages/maciek.github.io/audio-compression/21-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/audio-compression/21.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p>Since, the Mp3 compression process had padded the start and finish of the file, it is necessary to remove the silence so that both tracks are aligned.</p> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/audio-compression/31-480.webp 480w, /_pages/maciek.github.io/audio-compression/31-800.webp 800w, /_pages/maciek.github.io/audio-compression/31-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/audio-compression/31.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p>It’s quite slow and notorious to align both tracks as audacity does not support a user-friendly zoom in/out option. However, once you managed to zoom in so that you can see all the individual samples, I suggest to pick one that is standing out, and use it as a guide-sample.</p> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/audio-compression/41-480.webp 480w, /_pages/maciek.github.io/audio-compression/41-800.webp 800w, /_pages/maciek.github.io/audio-compression/41-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/audio-compression/41.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p>Now the interesting part kicks in. I selected the whole region of the 320kbps Mp3 and inverted it. It means that whenever the waveform had previously gone up it now is going down, and vice versa.</p> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/audio-compression/51-480.webp 480w, /_pages/maciek.github.io/audio-compression/51-800.webp 800w, /_pages/maciek.github.io/audio-compression/51-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/audio-compression/51.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p>Then I selected the uncompressed wave file with the inverted Mp3, and clicked mix and render.</p> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/audio-compression/61-480.webp 480w, /_pages/maciek.github.io/audio-compression/61-800.webp 800w, /_pages/maciek.github.io/audio-compression/61-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/audio-compression/61.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p>This action created a mix file that represents the differences between our uncompressed and compressed files. I think it’s really interesting to see this pretty digital representation of the data chunk that we loose completely when compressing our CD files. This is how it sounds like: <audio controls="" src="./stage1_T1.wav"></audio></p> <p>Cool, right? Does it make a difference? :)</p> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/audio-compression/71-480.webp 480w, /_pages/maciek.github.io/audio-compression/71-800.webp 800w, /_pages/maciek.github.io/audio-compression/71-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/audio-compression/71.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p>Then I imported a 320kbps Mp3 into Audacity. In the screenshot above you can see very clearly (on the same zoom-in setting on both tracks) differences in the sizes of both files. After this, I did the sample alignment again, and hit the play button. Both tracks plated simultaneously and sounded like the source CD. Mathematically, it was the source CD. The difference file and the compressed file equaled the source file. By muting the difference file at any point in the song, I could hear without distortion, or changes in volume, what is the difference in quality after compressing a wave file into a 320kbps Mp3.</p> <p>I listened, and listened, but there was no difference to be heard. Don’t believe me? See if you can spot the points where the quality changes.</p> <center> <figure> <figure> <audio src="/_pages/maciek.github.io/audio-compression/stage1_T2.mp3" controls=""/> </figure> </figure> </center> <p>Did you hear any difference? No? Yes? Maybe? Try it again and listen for an increase in quality at 5 seconds which disappears at 16. Using modern Mp3 encoding methods, a 320 bit rate Mp3 sounds very much like the original (at least to my ears).</p> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/audio-compression/81-480.webp 480w, /_pages/maciek.github.io/audio-compression/81-800.webp 800w, /_pages/maciek.github.io/audio-compression/81-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/audio-compression/81.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p>I repeated the same test using a VBR Mp3 instead of the normal 320kbps. As you can see the difference file is smaller from the normal 320 bitrate Mp3. You can listen to it and see if there is any detectable change in playback quality.</p> <center> <figure> <figure> <audio src="/_pages/maciek.github.io/audio-compression/stage2_T3.mp3" controls=""/> </figure> </figure> </center> <p>The quality should increase slightly after 5 seconds, then drop off at 16. I cannot hear any difference here as well. So does it mean that the 320kbps MPS sounds as good as an uncompressed CD .wav format?</p> <p>In order to do a more obvious comparison I did the same test using a 56 bit rate Mp3 and the results were, as expected, humongous. The difference track was huge. You could really see how much audio was lost in compression. The 56 bit rate audio sounded horrible, but as soon as I unmuted the difference track it was suddenly sounding like the CD once again. You can hear it for yourself here.</p> <center> <figure> <figure> <audio src="/_pages/maciek.github.io/audio-compression/stage3_T4.mp3" controls=""/> </figure> </figure> </center> <p>In the end, I have to say that it is (almost) impossible to tell the difference between a song as an uncompressed wave file and a song that has been compressed as 320 VBR. I used DT 770s and my M-audio interface for these tests, and of course all results were confirmed using my teenage ears. Furthermore, the 320 VBR file I used wighted 8.2 MB, the normal CBR Mp3 weighted 10.3 MB, and the uncompressed wave weighted 45.4 MB. This shows that the VBR method provides great results while taking 25.6% less space than a normal CBR method in this example.</p> <p>I think many people are not 100% honest with themselves when they say that all Mp3s sound worse than CDs. This goes especially for people with worn out ears who speak such heresies. On the contrary, I’ve read a few interesting posts where audiophiles argued that the average person doesn’t have the knowledge or experience to verbalize the fact that what they hear is an MP3. I don’t think that is the case in the kind of tests I conducted, as I tried it on few other recordings, and all the findings were the same. However, it may vary in more surgical audio situations where a trained ear, that knows exactly what to look for in the high frequencies, will be able to distinguish between a wave file and Mp3. Often, it will be the ’air’ of high frequencies that may provide some small differences between a good quality MP3 and a .wav file.</p> <p>Speaking of recording, mixing and mastering though… I would never include good quality Mp3 files in my mixes because I believe there are certain situations that ask for certain tools. I’d try to keep my recordings the highest quality possible, but that also may change depending on a final, envisioned version of a song I’ll mix.</p> <p>Again, Mp3 algorithms improved drastically over the past decade. We do not suffer anymore from tons of audio errors if an Mp3 is ‘only’ 192kbps. In fact, I’m positive that dropping to 128kbps would still be acceptable for many people. Especially if played on poor playback platforms such as iPods, iPods or similar, where listening conditions aren’t great anyways. I think we should admit however, that correctly compressed, high quality Mp3s are good enough to satisfy the needs of serious music listeners. Listeners who strive for a really good quality sounds that can be expressed through some expensive equipment.</p> <p>I’m also attaching this little section here, as I find it really fascinating how the same file compression comparison test can be shown visually.</p> <p>So here is an alternative way of looking at compression subject.</p> <p><a title="Lossy Audio Codec's Comparison" href="http://www.head-fi.org/t/225356/lossy-audio-codecs-comparison-huge-amount-of-pics-itunes-update-on-p-7" target="_blank">Lossy Audio Codec’s Comparison</a></p> <p>Another interesting visual example.</p> <p><a title="How to check quality of Mp3 file" href="http://www.walterdevos.be/how-to-check-quality-of-mp3-file" target="_blank">How to check quality of Mp3 file</a></p> <p>I’d like to thank <a id="yui-gen18" title="Bugbrain's post on Recordingreview.com" href="http://forum.recordingreview.com/f8/endless-mp3-vs-wav-debate-randomized-blind-listening-test-40661/" target="_blank" rel="nofollow">Bugbrain</a>, <a title="Forum profile" href="http://www.head-fi.org/u/49722/sir-nobax" target="_blank">Nobax</a>, <a title="Walter's blog" href="http://blog.walterdevos.be/" target="_blank">Walter</a>, and <a title="Jax's website" href="http://www.jax184.com/" target="_blank">Jax</a> for inspiring me to conduct this experiment.</p> <p>Maciek</p>]]></content><author><name></name></author><category term="lossy-compression"/><category term="MP3"/><category term="listening-tests"/><summary type="html"><![CDATA[On what's left out when compressing to MP3.]]></summary></entry><entry><title type="html">Audio Ripping and Compression</title><link href="https://maciek-tomczak.github.io/blog/2014/Audio-Ripping-and-Compression/" rel="alternate" type="text/html" title="Audio Ripping and Compression"/><published>2014-12-19T00:00:00+00:00</published><updated>2014-12-19T00:00:00+00:00</updated><id>https://maciek-tomczak.github.io/blog/2014/Audio-Ripping-and-Compression</id><content type="html" xml:base="https://maciek-tomczak.github.io/blog/2014/Audio-Ripping-and-Compression/"><![CDATA[<p>Bare in mind I wrote the following article back when I was an undergrad finishing my first year at Birmingham City University in 2013.</p> <p>Original article is posted <a href="https://maciekonsound.wordpress.com/2014/12/19/audio-ripping-and-compression/">here</a>.</p> <h4 id="audio-ripping-and-compression">Audio Ripping and Compression</h4> <p style="text-align:left;" align="CENTER">Recently I’ve been really interested in the whole talk about audio quality. I really value ‘good’ quality recordings and cherish the moments when I have access to these, but I was never too obsessed about it. Everyone will have their own interpretation of what sounds good anyways. Ha! And that is what’s really interesting.</p> <p>While I do not lament when I sometimes listen to 128kbps Mp3 files, I believe it is important to be able to compress audio files correctly because the poorly processed ones can ruin our ears forever… Or, for example, negate the advantages of an expensive speaker set that we may use.</p> <p>So I will present a method of audio ripping that will allow anyone to be left with a really good quality compressed files, as well as a little experiment, which hopefully will once and for all, save me from wasting my time thinking about differences in quality between an uncompressed audio file and a ‘correctly’ compressed Mp3 file.</p> <p>The first step is to find a CD that you would like to burn and then check it for any possible scratches. CDs are made from polycarbonate plastic (Macrolon) which is a sturdy and strong material that sadly scratches quite easily. The designers saw that coming and planned for it. The Red Book Standards for Audio Compact Discs enforces an error correction system that allows CD players to deduce a surprising amount of data based on the data which comes before and after a scratch.</p> <p>Furthermore, the data is not stored on the shiny part of the CD, but is actually stored on the label side (the program area). The CD player’s laser has to make its way through a layer of plastic till it reaches the disc’s data. So after all, a small scratch on the back surface of a CD is not as dangerous as it may seem.</p> <p>OK, so if you got that far and think that few facts about the program area of a CD will spoil this reading then just skip to the next paragraph… The program area of a CD also conforms to Red Book standards. Data is stored internally in a series of “bumps” known as “pits”. These pits are located in a single spiral track of TDM (time-division multiplexing) data. The data pits come in 8 different lengths: from 0.833μm to 3.56μm. The varying length and distance between the pits is how the digital audio information is stored in NRZI (the NRZI stands for non-return to zero inverted and is one of the most popular languages used for Pulse Code Modulation (PCM)).</p> <p>So, once you’ve chosen a CD that you are satisfied with, you will need a piece of software that will allow you to rip and compress it. I’m using <a title="Switch Audio File Converter Software" href="http://www.nch.com.au/switch/index.html" target="_blank">Switch</a>, which works both on pc and mac. Once you have opened any reasonable audio file converter software then I would take a moment, and poke around the encoding tab. It should look like this.</p> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/audio-ripping/1-480.webp 480w, /_pages/maciek.github.io/audio-ripping/1-800.webp 800w, /_pages/maciek.github.io/audio-ripping/1-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/audio-ripping/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p>These are the settings I’d use for creating high quality Mp3s. I’ll write a little bit about the details after.</p> <p>Encoder itself is one of the applications to encode audio to Mp3 files so they take far less storage space. This is called lossy compression. On that note, many people think compression equals a reduction in data and quality let say Mp3, MPEG, DTS and JPEG. Well, this is not always the case. Few examples of lossless compression: ZIP, RAR, TIFF, MLP. But back to the encoder. The encoder uses two different compression methods namely, CBR or VBR (see above settings).</p> <p>CBR stands for constant bit rate, which basically means that you tell the encoder to express every second of audio with a certain number of bits, and it does just that. It will give every single second of audio the same amount of space. There is nothing really bad about this method, it is simply very wasteful and produces bigger file sizes than VBR. Hence, somebody smart came up with another method called VBR.</p> <p>VBR stands for variable bit rate and is the most commonly used encoding type. With VBR the encoder considers every section of audio very carefully and decides how many bits it would take to encode it with the desired level of quality. This means that the bit rate can actually drop to almost nothing in the parts where there is silence, shoot up to high hundreds when the song starts, and peak at the limits of the encoder during particularly delicate passages.</p> <p>Mode in the stereo encoding section, I would leave on joint stereo as it offers better quality. In the joint stereo the encoder can spend the available bits more efficiently than normal stereo mode. There is a technique involved known as<a title="Joint Frequency Encoding" href="http://en.wikipedia.org/wiki/Joint_(audio_engineering)" target="_blank"> joint frequency encoding</a>, which functions on principle of <a title="Sound localization" href="http://en.wikipedia.org/wiki/Sound_localization" target="_blank">sound localization</a>. It stores one channel as the difference from the other as opposed to an entire second audio stream.</p> <p>Quality is the deceiving one. It basically tells the encoder how many shortcuts can it take during the analysis and compression process. When (q=0) the encoder does everything super accurately. When you set it to 9 it will do everything in a more ‘clumsy’ manner. The technology has moved by quite a lot since 1993, so nobody would really use low quality encoding today.</p> <p>CRC stands for a cyclic redundancy check and is an error-detecting code commonly used in digital networks and storage devices. I don’t know what real advantage it will bring to this compression process so leaving it alone, and unchecked should be completely acceptable.</p> <p>If I’m using a VBR then I want the encoder to have access to the widest range of bit rates possible. The minimum should be at 32 and the maximum should be at 320.</p> <p>The output sample rate is not shown in this window but I know it is going to be the original CD sample rate, which again thanks to the Red Book Standards, is said to be 44,100kHz.</p> <p>OK, lets get down to business.</p> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/audio-ripping/2-480.webp 480w, /_pages/maciek.github.io/audio-ripping/2-800.webp 800w, /_pages/maciek.github.io/audio-ripping/2-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/audio-ripping/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p>Above you can see all loaded tracks in .aiff file format. All that’s left to do is to click convert and all the magic will be done for us.</p> <center> <figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /_pages/maciek.github.io/audio-ripping/3-480.webp 480w, /_pages/maciek.github.io/audio-ripping/3-800.webp 800w, /_pages/maciek.github.io/audio-ripping/3-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/_pages/maciek.github.io/audio-ripping/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </figure> </center> <p>The conversion of all the files will take a while. After the conversion finishes, you are done. You’ve just converted losses CD files into a ‘very good’ quality lossy files. OK, but that’s still just talking. So in the<a title="Listening Tests" href="/maciek.github.io/Audio-Compression-Quality/"> next post</a> I’ll test how good they actually are when compared.</p> <p>Maciek</p>]]></content><author><name></name></author><category term="lossy-compression"/><category term="MP3"/><category term="cd-ripping"/><summary type="html"><![CDATA[On how I like my MP3s to be compressed.]]></summary></entry></feed>